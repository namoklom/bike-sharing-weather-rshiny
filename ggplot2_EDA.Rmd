---
title: "ggplot2 EDA"
output: html_document
---

# **Exploratory Data Analysis with tidyverse and ggplot2**

# Introduction and Objectives
This lab involves using an R notebook to perform exploratory data analysis (EDA) on the SEOUL BIKE SHARING dataset, utilizing the tidyverse and ggplot2 packages. The process begins with minor data preparation, followed by generating and exploring summary statistics from the processed dataframe. Subsequent steps include making observations based on these statistics and creating informative visualizations with ggplot2.

Visualization serves as a powerful tool for understanding data and identifying underlying patterns. Scatterplots, for example, can illustrate the correlation between two features. When variables are highly correlated, they tend to vary similarly, meaning one variable’s variation can partially explain the other's. Such covariates may have causal relationships, where a change in one variable directly causes a change in another; however, correlations do not necessarily imply causation. In some cases, an external factor may influence both variables, or the relationship could be coincidental. Recognizing causal links allows for actionable insights—like controlling a light switch to turn a bulb on or off—where influencing one variable results in a predictable change in the other. This concept is central to advanced data science but goes beyond the scope of this lab.

Visualization also aids in detecting outliers and anomalies. Boxplots are particularly useful for revealing these irregularities, while direct plotting of variables such as time series or spatial data can expose trends and unusual patterns. However, outliers can dominate the scale of plots, making the data appear flat or uninformative, so data cleaning including outlier removal may be necessary for clearer analysis.

A cautionary note: patterns identified in small datasets should be treated skeptically. While any two randomly placed points define a line, the likelihood that additional points align perfectly is low. This underscores an advantage of big data, where observed patterns are more likely to generalize to new data.

With this understanding, the exploratory analysis can proceed to uncover meaningful insights from the dataset.



### For reference, we include the Attribute Information for the `seoul_bike_sharing` dataset:

- DATE - format: "2017-12-01"
- RENTED_BIKE_COUNT - Count of bikes rented at each hour
- HOUR - Hour of the day
- TEMPERATURE - Celsius
- HUMIDITY - %
- Windspeed - m/s
- VISIBILITY - 10m
- DEW_POINT_TEMPERATURE - Celsius
- SOLAR_RADIATION - MJ/m2
- RAINFALL - mm
- SNOWFALL - cm
- SEASONS -  "Autumn","Spring",..
- HOLIDAY - "Holiday", "No holiday"
- FUNCTIONING_DAY - "Yes", "No"



## Load the seoul_bike_sharing data into a dataframe

The dataset can be loaded from the provided URL. Although the dataset is already clean, attention must be paid to data types, particularly date columns, which may require coercion to the appropriate date format. Additionally, categorical variables should be explicitly converted to factor data types to ensure proper handling during analysis and visualization.

```R
seoul_bike_sharing <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/seoul_bike_sharing.csv"  

```


### Task 1 - Load the dataset
When loading the dataset, the DATE column should be initially read as a character type. This approach allows for explicit control over converting it later to a proper date format as needed during data preparation.

### Solution 1


```{r}
library(tidyverse)

url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/seoul_bike_sharing.csv"

seoul_bike_sharing <- read_csv(url,
                               col_types = cols(
                                 DATE = col_character(),
                                 RENTED_BIKE_COUNT = col_double(),
                                 HOUR = col_double(),
                                 TEMPERATURE = col_double(),
                                 HUMIDITY = col_double(),
                                 WIND_SPEED = col_double(),
                                 VISIBILITY = col_double(),
                                 DEW_POINT_TEMPERATURE = col_double(),
                                 SOLAR_RADIATION = col_double(),
                                 RAINFALL = col_double(),
                                 SNOWFALL = col_double(),
                                 SEASONS = col_factor(),
                                 HOLIDAY = col_factor(),
                                 FUNCTIONING_DAY = col_factor()
                               ))


glimpse(seoul_bike_sharing)
head(seoul_bike_sharing)
```

### Task 2 - Recast `DATE` as a date
Use the format of the data, namely "%d/%m/%Y".
### Solution 2


```{r}
seoul_bike_sharing <- seoul_bike_sharing %>%
  mutate(DATE = as.Date(DATE, format = "%d/%m/%Y"))
```

### Task 3 - Cast `HOURS` as a categorical variable
Also, coerce its levels to be an ordered sequence.  This will ensure our visualizations correctly utilize `HOURS` as a discrete variable with the expected ordering.  
### Solution 3


```{r}
seoul_bike_sharing <- seoul_bike_sharing %>%
  mutate(HOUR = factor(HOUR, levels = 0:23, ordered = TRUE))
```

### Check the structure of the dataframe


```{r}
str(seoul_bike_sharing)
```

### Finally, ensure there are no missing values


```{r}
sum(is.na(seoul_bike_sharing))
```

## Descriptive Statistics

The dataset seoul_bike_sharing is ready for exploration, allowing the generation of high-level summary statistics that provide an overview of its contents, distributions, and potential anomalies. This initial statistical insight forms the foundation for deeper exploratory data analysis and visualization.

### Task 4 - Dataset Summary
Use the base R `sumamry()` function to describe the `seoul_bike_sharing` dataset.

### Solution 4


```{r}
summary(seoul_bike_sharing)
```

### Some Basic Observations:
- We can see from `DATE` that we have exactly a full year of data.  
- No records have zero bike counts.  
- Spring and Winter have the same count of records, while autumn has the least and Summer has the most.
- Temperature has a large range, so we might expect it to explain at least some of the variation in bike rentals.  
- Precipitation seems to be quite rare, only happening in the fourth quartiles for both `RAINFALL` and `SNOWFALL`.
- The average `WINDSPEED` is very light at only 1.7 m/s, and even the maximum is only a moderate breeze (Google 'Beaufort Wind Scale' to find the different wind descriptions)  

Exploratory Data Analysis often raises more questions than it answers, which is a valuable part of the process. This iterative exploration leads to a deeper understanding of the data’s nuances and complexities, ultimately enriching the overall analysis and guiding subsequent steps more effectively.

### Task 5 - Based on the above stats, calculate how many Holidays there are.
### Solution 5:


```{r}
table(seoul_bike_sharing$HOLIDAY)
```

### Task 6 - Calculate the percentage of records that fall on a holiday.
### Solution 6


```{r}
holiday_counts <- table(seoul_bike_sharing$HOLIDAY)
holiday_percentage <- (holiday_counts["Holiday"] / sum(holiday_counts)) * 100
holiday_percentage
```

### Task 7 - Given there is exactly a full year of data, determine how many records we expect to have.
### Solution 7


```{r}
expected_records <- 24 * 365
expected_records
```

### Task 8 - Given the observations for the 'FUNCTIONING_DAY' how many records must there be?
### Solution 8


```{r}
table(seoul_bike_sharing$FUNCTIONING_DAY)
```

## Drilling Down
Let's calculate some seasonally aggregated measures to help build some more context.  
### Task 9 - Load the dplyr package, group the data by `SEASONS`, and use the `summarize()` function to calculate the seasonal total rainfall and snowfall.
### Solution 9


```{r}
library(dplyr)

seasonal_precipitation <- seoul_bike_sharing %>%
  group_by(SEASONS) %>%
  summarize(
    total_rainfall = sum(RAINFALL, na.rm = TRUE),
    total_snowfall = sum(SNOWFALL, na.rm = TRUE)
  )

seasonal_precipitation
```

## Data Visualization

Let's take a closer look at our main variable of interest, namely, `RENTED_BIKE_COUNT`.  
Think of this variable as the key _measure_ or _dependent variable_ in our analysis.  

Indeed, it is a measured quantity, and we expect it to depend on factors such as the expected weather.  
Evidently, if the immediate or forecasted weather is harsh or unpleasant, many people could choose to use alternate transit or simply wait for better weather rather than rent a bike.   
On the other hand, many people may be inspired to ride under pleasant expected weather conditions.  

The weather is largely infuenced by the time of day and the seasons, so these are also factors.  
The time of day, the day of week, and Holidays all matter because they control commuting schedules.  

Finer granularity data such as a unique ID for each bike and/or rider, when and where each bike was rented, or even finer - a history of when and where each bike was used or idle - would be interesting as well.


### Load the ggplot2 package so we can generate some data visualizations.


```{r}
library(ggplot2)
```

Our variable of interest is a time series, so why not start by taking a look at it in it's natural form?

### Task 10 - Create a scatter plot of `RENTED_BIKE_COUNT` vs `DATE`.
Tune the opacity using the `alpha` parameter such that the points don't obscure each other too much.
### Solution 10


```{r}
ggplot(seoul_bike_sharing, aes(x = DATE, y = RENTED_BIKE_COUNT)) +
  geom_point(alpha = 0.3, color = "purple") +
  labs(title = "Bike Rentals Over Time",
       x = "Date",
       y = "Rented Bike Count") +
  theme_light()
```

### Using colour
Let's see if we can enhance some of these features by incorporating colour. Given our observations so far, `HOURS` is a great candidate for this task.  

### Task 11 - Create the same plot of the `RENTED_BIKE_COUNT` time series, but now add `HOURS` as the colour.
### Solution 11


```{r}
ggplot(seoul_bike_sharing, aes(x = DATE, y = RENTED_BIKE_COUNT, color = as.factor(HOUR))) +
  geom_point(alpha = 0.5) +
  labs(title = "Bike Rentals Over Time Colored by Hour",
       x = "Date",
       y = "Rented Bike Count",
       color = "Hour") +
  theme_minimal()
```

## Distributions


### Task 12 - Create a histogram overlaid with a kernel density curve
Normalize the histogram so the y axis represents 'density'. This can be done by setting `y=..density..` in the aesthetics of the histogram.


### Solution 12


```{r}
ggplot(seoul_bike_sharing, aes(x = RENTED_BIKE_COUNT)) +
  geom_histogram(aes(y = ..density..), binwidth = 50, fill = "skyblue", color = "black", alpha = 0.6) +
  geom_density(color = "red", size = 1) +
  labs(title = "Histogram and Kernel Density of Rented Bike Count",
       x = "Rented Bike Count",
       y = "Density") +
  theme_minimal()
```

## Correlation between two variables (scatter plot)
### Task 13 - Use a scatter plot to visualize the correlation between `RENTED_BIKE_COUNT` and `TEMPERATURE` by `SEASONS`.
Start with `RENTED_BIKE_COUNT` vs. `TEMPERATURE`, then generate four plots corresponding to the `SEASONS` by adding a `facet_wrap()` layer.
Also, make use of colour and opacity to emphasize any patterns that emerge. Use `HOUR` as the color.

### Solution 13


```{r}
ggplot(seoul_bike_sharing, aes(x = TEMPERATURE, y = RENTED_BIKE_COUNT, color = as.factor(HOUR))) +
  geom_point(alpha = 0.5) +
  facet_wrap(~ SEASONS) +
  scale_color_viridis_d(name = "Hour") +
  labs(title = "Correlation of Rented Bike Count and Temperature by Season",
       x = "Temperature (°C)",
       y = "Rented Bike Count") +
  theme_minimal()
```

```{r}
ggplot(seoul_bike_sharing) +
   geom_point(aes(x=TEMPERATURE,y=RENTED_BIKE_COUNT,colour=HOUR),alpha=1/5)
```

## Outliers (boxplot)
### Task 14 - Create a display of four boxplots of `RENTED_BIKE_COUNT` vs. `HOUR` grouped by `SEASONS`.
Use `facet_wrap` to generate four plots corresponding to the seasons.

### Solution 14


```{r}
ggplot(seoul_bike_sharing, aes(x = HOUR, y = RENTED_BIKE_COUNT)) +
  geom_boxplot() +
  facet_wrap(~ SEASONS) +
  labs(title = "Boxplots of Rented Bike Count by Hour and Season",
       x = "Hour of Day",
       y = "Rented Bike Count") +
  theme_minimal()
```

### Task 15 - Group the data by `DATE`, and use the summarize() function to calculate the daily total rainfall and snowfall.
Also, go ahead and plot the results.
### Solution 15


```{r}
daily_precipitation <- seoul_bike_sharing %>%
  group_by(DATE) %>%
  summarize(
    total_rainfall = sum(RAINFALL, na.rm = TRUE),
    total_snowfall = sum(SNOWFALL, na.rm = TRUE)
  )

ggplot(daily_precipitation, aes(x = DATE)) +
  geom_line(aes(y = total_rainfall, color = "Rainfall")) +
  geom_line(aes(y = total_snowfall, color = "Snowfall")) +
  labs(title = "Daily Total Rainfall and Snowfall",
       x = "Date",
       y = "Total (mm)") +
  scale_color_manual(name = "Precipitation Type",
                     values = c("Rainfall" = "blue", "Snowfall" = "grey")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Task 16 - Determine how many days had snowfall.
### Solution 16


```{r}
days_with_snowfall <- daily_precipitation %>%
  filter(total_snowfall > 0) %>%
  nrow()

days_with_snowfall
```
